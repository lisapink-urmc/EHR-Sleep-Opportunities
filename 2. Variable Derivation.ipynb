{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd4d8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import  time, datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03587dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in CSVs\n",
    "pat_nights = pd.read_csv('Queried_Final/patient_night_population.csv')\n",
    "pat_nights = pat_nights.drop_duplicates(subset=['PAT_ENC_CSN_ID', 'NIGHT_START', 'NIGHT_END'])\n",
    "on_unit_interruptions = pd.read_csv('Queried_Final/on_unit_interruptions.csv')\n",
    "off_unit_interruptions = pd.read_csv('Queried_Final/off_unit_interruptions.csv')\n",
    "off_unit_interruptions.rename(columns={'START_TIME': 'TIME'}, inplace=True)\n",
    "flowsheets = pd.read_csv('Queried_Final/flowsheets.csv')\n",
    "labs = pd.read_csv('Queried_Final/labs_and_imaging.csv')\n",
    "meds = pd.read_csv('Queried_Final/medication_administration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cf2de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickled_dataframes/off_unit_interruptions_df', 'rb') as f:\n",
    "    off_unit_interruptions = pickle.load(f)\n",
    "    \n",
    "with open('pickled_dataframes/on_unit_interruptions_df', 'rb') as f:\n",
    "    on_unit_interruptions = pickle.load(f)\n",
    "    \n",
    "with open('pickled_dataframes/patient_night_population_df', 'rb') as f:\n",
    "    pat_nights = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c5fc857",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_nights = pat_nights.drop_duplicates(subset=['PAT_ENC_CSN_ID', 'NIGHT_START', 'NIGHT_END'])\n",
    "off_unit_interruptions.rename(columns={'START_TIME': 'TIME'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d437096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile count_ppis_by_pat_nights.py\n",
    "\n",
    "def drop_duplicates(df, time_column):\n",
    "    df_copy = df.copy()\n",
    "    df_unique = df_copy.drop_duplicates(\n",
    "      subset = ['PAT_ENC_CSN_ID', time_column],\n",
    "      keep = 'last').reset_index(drop = True)\n",
    "\n",
    "    df_unique = df_unique[['PAT_ENC_CSN_ID', time_column]]\n",
    "    df_unique = df_unique.rename({time_column: 'TIME'}, axis=1)\n",
    "    \n",
    "    return df_unique\n",
    "\n",
    "def extract_vitals_neuros(flowsheets_df):\n",
    "    vitals = flowsheets[(flowsheets['ROW_NAME']=='BP') | \n",
    "                          (flowsheets['ROW_NAME']=='Pulse') |\n",
    "                          (flowsheets['ROW_NAME']=='Temp') |\n",
    "                          (flowsheets['ROW_NAME']=='SpO2') |\n",
    "                          (flowsheets['ROW_NAME']=='BG (glucometer)')]\n",
    "    \n",
    "    neuros = flowsheets[(flowsheets['GROUP_NAME']=='GCS and Neuro Checks') | \n",
    "                          (flowsheets['GROUP_NAME']=='Neuro Checks')]\n",
    "    return vitals, neuros\n",
    "\n",
    "def extract_meds(meds):\n",
    "    taken_meds = meds[(meds['MAR_ACTION'] != 'Canceled Entry') &\n",
    "                     (meds['MAR_ACTION'] != 'Held') & \n",
    "                     (meds['MAR_ACTION'] != 'Rate Verify')]\n",
    "    return taken_meds\n",
    "\n",
    "def prepare_ppi_df(vitals_df, neuros_df, meds_df, labs_df, off_unit_df, on_unit_df):\n",
    "    \n",
    "    vitals_df['TIME'] = pd.to_datetime(vitals_df['TIME'])\n",
    "    vitals_df['END_TIME'] = vitals_df['TIME']  + timedelta(minutes=5)\n",
    "    neuros_df['TIME'] = pd.to_datetime(neuros_df['TIME'])\n",
    "    neuros_df['END_TIME'] = neuros_df['TIME']  + timedelta(minutes=5)\n",
    "    meds_df['TIME'] = pd.to_datetime(meds_df['TIME'])\n",
    "    meds_df['END_TIME'] = meds_df['TIME']  + timedelta(minutes=5)\n",
    "    labs_df['TIME'] = pd.to_datetime(labs_df['TIME'])\n",
    "    labs_df['END_TIME'] = labs_df['TIME']  + timedelta(minutes=5) \n",
    "    off_unit_df['TIME'] = pd.to_datetime(off_unit_df['TIME'])\n",
    "    off_unit_df['END_TIME'] = pd.to_datetime(off_unit_df['END_TIME']) \n",
    "    on_unit_df['TIME'] = pd.to_datetime(on_unit_df['TIME'])\n",
    "    on_unit_df['END_TIME'] = on_unit_df['TIME']  + timedelta(minutes=5)\n",
    "    \n",
    "    vitals_df['PPI_TYPE'] = 'Vitals'\n",
    "    neuros_df['PPI_TYPE'] = 'Neuros'\n",
    "    meds_df['PPI_TYPE'] = 'Meds'\n",
    "    labs_df['PPI_TYPE'] = 'Labs & Imaging'\n",
    "    off_unit_df['PPI_TYPE'] = 'Off Unit'\n",
    "    on_unit_df['PPI_TYPE'] = 'On Unit'\n",
    "    \n",
    "    vitals_id_list = vitals_df.PAT_ENC_CSN_ID.values.tolist()\n",
    "    vitals_start_time_list= [time.strftime('%Y-%m-%d %H:%M:%S') for time in vitals_df['TIME']]\n",
    "    vitals_end_time_list= [time.strftime('%Y-%m-%d %H:%M:%S') for time in vitals_df['END_TIME']]\n",
    "    vitals_ppi_list= vitals_df.PPI_TYPE.values.tolist()\n",
    "\n",
    "    neuros_id_list = neuros_df.PAT_ENC_CSN_ID.values.tolist()\n",
    "    neuros_start_time_list = [time.strftime('%Y-%m-%d %H:%M:%S') for time in neuros_df['TIME']]\n",
    "    neuros_end_time_list= [time.strftime('%Y-%m-%d %H:%M:%S') for time in neuros_df['END_TIME']]\n",
    "    neuros_ppi_list = neuros_df.PPI_TYPE.values.tolist()\n",
    "\n",
    "    meds_id_list = meds_df.PAT_ENC_CSN_ID.values.tolist()\n",
    "    meds_start_time_list = [time.strftime('%Y-%m-%d %H:%M:%S') for time in meds_df['TIME']]\n",
    "    meds_end_time_list= [time.strftime('%Y-%m-%d %H:%M:%S') for time in meds_df['END_TIME']]\n",
    "    meds_ppi_list = meds_df.PPI_TYPE.values.tolist()\n",
    "\n",
    "    labs_id_list = labs_df.PAT_ENC_CSN_ID.values.tolist()\n",
    "    labs_start_time_list = [time.strftime('%Y-%m-%d %H:%M:%S') for time in labs_df['TIME']]\n",
    "    labs_end_time_list= [time.strftime('%Y-%m-%d %H:%M:%S') for time in labs_df['END_TIME']]\n",
    "    labs_ppi_list = labs_df.PPI_TYPE.values.tolist()\n",
    "    \n",
    "    off_unit_id_list = off_unit_df.PAT_ENC_CSN_ID.values.tolist()\n",
    "    off_unit_start_time_list = [time.strftime('%Y-%m-%d %H:%M:%S') for time in off_unit_df['TIME']]\n",
    "    off_unit_end_time_list= [time.strftime('%Y-%m-%d %H:%M:%S') for time in off_unit_df['END_TIME']]\n",
    "    off_unit_ppi_list = off_unit_df.PPI_TYPE.values.tolist()\n",
    "    \n",
    "    on_unit_id_list = on_unit_df.PAT_ENC_CSN_ID.values.tolist()\n",
    "    on_unit_start_time_list = [time.strftime('%Y-%m-%d %H:%M:%S') for time in on_unit_df['TIME']]\n",
    "    on_unit_end_time_list= [time.strftime('%Y-%m-%d %H:%M:%S') for time in on_unit_df['END_TIME']]\n",
    "    on_unit_ppi_list = on_unit_df.PPI_TYPE.values.tolist()\n",
    "\n",
    "    id_list = vitals_id_list + meds_id_list + neuros_id_list + labs_id_list + off_unit_id_list + on_unit_id_list\n",
    "    start_time_list = vitals_start_time_list  + meds_start_time_list + neuros_start_time_list + labs_start_time_list + off_unit_start_time_list + on_unit_start_time_list\n",
    "    end_time_list = vitals_end_time_list + meds_end_time_list + neuros_end_time_list + labs_end_time_list + off_unit_end_time_list + on_unit_end_time_list\n",
    "    ppi_list = vitals_ppi_list + meds_ppi_list + neuros_ppi_list + labs_ppi_list + off_unit_ppi_list + on_unit_ppi_list\n",
    "    \n",
    "    combined_df = {\n",
    "    'PAT_ENC_CSN_ID' : id_list,\n",
    "    'START_TIME' : start_time_list,\n",
    "    'END_TIME' : end_time_list,\n",
    "    'PPI_TYPE' : ppi_list\n",
    "    }\n",
    "    combined_df = pd.DataFrame(combined_df)\n",
    "    combined_df = combined_df.sort_values(by=['PAT_ENC_CSN_ID', 'START_TIME', 'END_TIME', 'PPI_TYPE'], ascending=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def filter_ppi_by_pat_nights(pat_nights, filtered_df, reset_index=True):\n",
    "    # Create an empty list to store the results\n",
    "    result = []\n",
    "\n",
    "    # Iterate through pat_nights rows\n",
    "    for idx, row in pat_nights.iterrows():\n",
    "        patient_id = row['PAT_ENC_CSN_ID']\n",
    "        start_time = row['NIGHT_START']\n",
    "        end_time = row['NIGHT_END']\n",
    "        \n",
    "        filtered_df['START_TIME'] = pd.to_datetime(filtered_df['START_TIME'])\n",
    "        filtered_df['END_TIME'] = pd.to_datetime(filtered_df['END_TIME'])\n",
    "\n",
    "        # Filter filtered_df for rows where TIME falls between START and END\n",
    "        filtered_rows = filtered_df[(filtered_df['PAT_ENC_CSN_ID'] == patient_id) & (filtered_df['START_TIME'] >= start_time) & (filtered_df['END_TIME'] <= end_time)]\n",
    "\n",
    "        # Append the filtered rows to the result list as a DataFrame\n",
    "        result.append(filtered_rows)\n",
    "\n",
    "    # Concatenate the DataFrames in the result list into a single DataFrame\n",
    "    ppi_df = pd.concat(result)\n",
    "\n",
    "    # Reset the index of the final DataFrame if reset_index is True\n",
    "    if reset_index:\n",
    "        ppi_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return ppi_df\n",
    "\n",
    "def count_ppis_by_pat_nights(pat_nights, ppi_df):\n",
    "    # Initialize an empty dictionary to store the result\n",
    "    result_dict = {}\n",
    "\n",
    "    # Iterate through pat_nights rows\n",
    "    for idx, row in pat_nights.iterrows():\n",
    "        patient_id = row['PAT_ENC_CSN_ID']\n",
    "        night_start = row['NIGHT_START']\n",
    "        night_end = row['NIGHT_END']\n",
    "\n",
    "        # Filter filtered_df for rows where TIME falls between START and END\n",
    "        filtered_rows = ppi_df[(ppi_df['PAT_ENC_CSN_ID'] == patient_id) & (ppi_df['START_TIME'] >= night_start) & (ppi_df['END_TIME'] <= night_end)]\n",
    "\n",
    "        # Store the filtered rows as a list in the result dictionary with the pat_nights index as the key\n",
    "        result_dict[idx] = filtered_rows.to_dict('records')\n",
    "\n",
    "    # Create a new DataFrame based on pat_nights and add a 'COUNT' column\n",
    "    result_df = pat_nights.copy()\n",
    "    result_df['COUNT'] = [len(result_dict[idx]) for idx in result_dict]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0908192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_duration(ppi_df, pat_nights):\n",
    "    # Convert 'START_TIME' and 'END_TIME' columns to datetime\n",
    "    ppi_df['START_TIME'] = pd.to_datetime(ppi_df['START_TIME'])\n",
    "    ppi_df['END_TIME'] = pd.to_datetime(ppi_df['END_TIME'])\n",
    "\n",
    "    # Initialize an empty list to store the result\n",
    "    durations_list = []\n",
    "\n",
    "    # Iterate through pat_nights rows\n",
    "    for _, row in pat_nights.iterrows():\n",
    "        patient_id = row['PAT_ENC_CSN_ID']\n",
    "        start_time = row['NIGHT_START']\n",
    "        end_time = row['NIGHT_END']\n",
    "\n",
    "        # Filter ppi_df for rows where 'START_TIME' or 'END_TIME' falls within the time span (NIGHT_START to NIGHT_END)\n",
    "        filtered_rows = ppi_df[(ppi_df['PAT_ENC_CSN_ID'] == patient_id) & (\n",
    "            (ppi_df['START_TIME'] >= start_time) & (ppi_df['START_TIME'] <= end_time) |\n",
    "            (ppi_df['END_TIME'] >= start_time) & (ppi_df['END_TIME'] <= end_time))]\n",
    "\n",
    "        # Sort and convert 'START_TIME' and 'END_TIME' to lists\n",
    "        all_times = sorted([[list(filtered_rows['START_TIME'])[x], list(filtered_rows['END_TIME'])[x]] for x in range(len(list(filtered_rows['END_TIME'])))])\n",
    "        \n",
    "        # Group times within 20 minutes of each other while keeping 'START_TIME' and 'END_TIME' together\n",
    "        current_group = []\n",
    "\n",
    "        for time in all_times:\n",
    "            if not current_group or time[0] < current_group[-1][1] or (time[0] - current_group[-1][1]).seconds / 60 <= 20:\n",
    "                current_group.append(time)\n",
    "            else:\n",
    "                # Append the duration of the group to the list\n",
    "                durations_list.extend([int((group[-1][1] - group[0][0]).seconds / 60) for group in [current_group]])\n",
    "                current_group = [time]\n",
    "        \n",
    "        if current_group:\n",
    "            # Append the duration of the last group to the list\n",
    "            durations_list.extend([int((group[-1][1] - group[0][0]).seconds / 60) for group in [current_group]])\n",
    "\n",
    "    return durations_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1f2d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_ppis(ppi_df, pat_nights):\n",
    "    # Convert 'TIME' and 'END_TIME' columns to datetime\n",
    "    ppi_df['START_TIME'] = pd.to_datetime(ppi_df['START_TIME'])\n",
    "    ppi_df['END_TIME'] = pd.to_datetime(ppi_df['END_TIME'])\n",
    "\n",
    "    # Initialize an empty dictionary to store the result\n",
    "    result_dict = {}\n",
    "\n",
    "    # Iterate through pat_nights rows\n",
    "    for idx, row in pat_nights.iterrows():\n",
    "        patient_id = row['PAT_ENC_CSN_ID']\n",
    "        start_time = row['NIGHT_START']\n",
    "        end_time = row['NIGHT_END']\n",
    "\n",
    "        # Filter ppi_df for rows where 'TIME' or 'END_TIME' falls within the time span (START to END)\n",
    "        filtered_rows = ppi_df[(ppi_df['PAT_ENC_CSN_ID'] == patient_id) & (\n",
    "            (ppi_df['START_TIME'] >= start_time) & (ppi_df['START_TIME'] <= end_time) |\n",
    "            (ppi_df['END_TIME'] >= start_time) & (ppi_df['END_TIME'] <= end_time))]\n",
    "        \n",
    "        \n",
    "        all_times = sorted([[list(filtered_rows['START_TIME'])[x], list(filtered_rows['END_TIME'])[x]] for x in range(len(list(filtered_rows['END_TIME'])))])\n",
    "\n",
    "        # Group times within 20 minutes of each other while keeping 'TIME' and 'END_TIME' together\n",
    "        grouped_times = []\n",
    "        current_group = []\n",
    "\n",
    "        for time in all_times:\n",
    "            if not current_group or time[0] < current_group[-1][1] or (time[0] - current_group[-1][1]).seconds / 60 <= 20:\n",
    "                current_group.append(time)\n",
    "            else:\n",
    "                grouped_times.append(current_group.copy())\n",
    "                current_group = [time]\n",
    "            \n",
    "\n",
    "        if current_group:\n",
    "            grouped_times.append(current_group)\n",
    "\n",
    "        # Append the grouped times to the result dictionary with the pat_nights index as the key\n",
    "        result_dict[idx] = grouped_times\n",
    "\n",
    "    # Create a new DataFrame with grouped times\n",
    "    result_df = pat_nights.copy()\n",
    "    result_df['GROUPED_TIMES'] = [result_dict[idx] for idx in result_dict]\n",
    "    result_df['NUM_EPISODES'] = result_df['GROUPED_TIMES'].apply(len)\n",
    "\n",
    "    return result_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "838f60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the biggest gap with a default of 420 minutes\n",
    "def calculate_luso(row):\n",
    "    grouped_times = row['GROUPED_TIMES']\n",
    "    start_time = row['NIGHT_START']\n",
    "    end_time = row['NIGHT_END']\n",
    "    start_time = pd.to_datetime(start_time)\n",
    "    end_time = pd.to_datetime(end_time)\n",
    "\n",
    "    # Flatten the list of grouped times\n",
    "    all_times = [time for sublist in grouped_times for time in sublist]\n",
    "\n",
    "    # Sort the times\n",
    "    all_times.sort()\n",
    "\n",
    "    # Calculate the gaps between times\n",
    "    gaps = [(all_times[i+1][0] - all_times[i][1]).total_seconds() / 60 for i in range(len(all_times)-1)]\n",
    "\n",
    "    # Check if gaps is empty and return the default value\n",
    "    if not gaps:\n",
    "        # Check if grouped_times is not empty (contains at least one group)\n",
    "        if grouped_times:\n",
    "            # Calculate the gap between the start time and the first timestamp\n",
    "            gap_start = (grouped_times[0][0][0] - start_time).total_seconds() / 60\n",
    "            # Calculate the gap between the last timestamp and the end time\n",
    "            gap_end = (end_time - grouped_times[0][-1][-1]).total_seconds() / 60\n",
    "\n",
    "            biggest_gap_start = start_time if gap_start > gap_end else grouped_times[0][-1][-1]\n",
    "            biggest_gap_duration = max(gap_start, gap_end)\n",
    "        else:\n",
    "            biggest_gap_duration, biggest_gap_start = 420, None  # Default of 420 minutes\n",
    "\n",
    "    else:\n",
    "        # Include the gaps between 'START' and the first time, and 'END' and the last time\n",
    "        if grouped_times:\n",
    "            gaps.insert(0, (grouped_times[0][0][0] - start_time).total_seconds() / 60)\n",
    "            gaps.append((end_time - grouped_times[-1][-1][-1]).total_seconds() / 60)\n",
    "\n",
    "        biggest_gap_index = np.argmax(gaps)\n",
    "\n",
    "        # Determine the start time of the biggest gap\n",
    "        if biggest_gap_index == 0:\n",
    "            biggest_gap_start = start_time\n",
    "        elif biggest_gap_index == len(gaps) - 1:\n",
    "            biggest_gap_start = grouped_times[-1][-1][-1]\n",
    "        else:\n",
    "            biggest_gap_start = all_times[biggest_gap_index-1][1]\n",
    "\n",
    "        biggest_gap_duration = gaps[biggest_gap_index]\n",
    "\n",
    "    # Set the values in the new columns\n",
    "    row['LUSO'] = biggest_gap_duration\n",
    "    row['LUSO_START'] = biggest_gap_start\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "050b4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals, neuros = extract_vitals_neuros(flowsheets)\n",
    "meds = extract_meds(meds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54168181",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuros = drop_duplicates(neuros, 'TIME')\n",
    "vitals = drop_duplicates(vitals, 'TIME')\n",
    "labs = drop_duplicates(labs, 'TIME')\n",
    "meds = drop_duplicates(meds, 'TAKEN_TIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e70a157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_df = prepare_ppi_df(vitals, neuros, meds, labs, off_unit_interruptions, on_unit_interruptions)\n",
    "ppi_df = filter_ppi_by_pat_nights(pat_nights, ppi_df)\n",
    "ppi_df['PPI_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad531d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_count_df = count_ppis_by_pat_nights(pat_nights, ppi_df)\n",
    "ppi_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea1fee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "luso_epcount = group_ppis(ppi_df, pat_nights)\n",
    "luso_epcount = luso_epcount.apply(calculate_luso, axis=1)\n",
    "luso_epcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67f7b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = get_episode_duration(ppi_df, pat_nights)\n",
    "columns = ['Interruptive Episode Duration']\n",
    "duration_df = pd.DataFrame(durations, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1681fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges and labels for the ranges\n",
    "bin_edges = [0, 60, 120, 180, 240, 300, 360, 420, 421]\n",
    "bin_labels = [f'{bin_edges[i]}-{(bin_edges[i+1])-1}' for i in range(len(bin_edges) - 1)]\n",
    "\n",
    "# Use pd.cut to create the LUSO_RANGE column\n",
    "luso_epcount['LUSO_RANGE'] = pd.cut(luso_epcount['LUSO'], bins=bin_edges, labels=bin_labels, right=False)\n",
    "luso_epcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "569768d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_eps = luso_epcount[luso_epcount['NUM_EPISODES']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4d12450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes to csv\n",
    "ppi_df.to_csv('Queried_Final/ppi_df.csv')\n",
    "ppi_count_df.to_csv('Queried_Final/ppi_count_df.csv')\n",
    "luso_epcount.to_csv('Queried_Final/luso_episodecount.csv')\n",
    "duration_df.to_csv('Queried_Final/episode_durations.csv')\n",
    "zero_eps.to_csv('Queried_Final/no_interruption_nights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7be0bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to a pickle file\n",
    "with open('luso_epcount.pkl', 'wb') as f:\n",
    "    pickle.dump(luso_epcount, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca997036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep_kernel",
   "language": "python",
   "name": "sleep_disturbances"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
