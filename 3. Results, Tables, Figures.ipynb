{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26962540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSVs\n",
    "psi_df = pd.read_csv('Created_Data/psi_df_without_transfer.csv')\n",
    "psi_count_df = pd.read_csv('Created_Data/psi_count_df.csv')\n",
    "off_unit_df = pd.read_csv('Created_Data/off_unit_transfers.csv')\n",
    "pat_nights = pd.read_csv('Created_Data/patient_night_population.csv')\n",
    "episode_durations = pd.read_csv('Created_Data/episode_durations.csv')\n",
    "admission_details = pd.read_csv('Queried_Final/admission_details.csv')\n",
    "luso_epcount = pd.read_csv('Created_Data/luso_episodecount.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f30882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique index for each patient night\n",
    "pat_nights.reset_index(inplace=True)\n",
    "pat_nights.rename(columns={'index': 'pat_night_index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e1ac96",
   "metadata": {},
   "source": [
    "### Table 1: Demographics of patients in the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47df482",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_details['PAT_ENC_CSN_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e04e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pat_encs = pat_nights['PAT_ENC_CSN_ID'].unique().tolist()\n",
    "len(unique_pat_encs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac39cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df = admission_details[admission_details['PAT_ENC_CSN_ID'].isin(unique_pat_encs)]\n",
    "demographics_df = demographics_df.drop_duplicates(subset=['PAT_ENC_CSN_ID'])\n",
    "demographics_df['PAT_ENC_CSN_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df['PAT_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e73756",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df = demographics_df.drop_duplicates(subset=['PAT_ID'])\n",
    "\n",
    "# Custom age ranges\n",
    "bins = [0, 50, 60, 70, 80, float('inf')]\n",
    "labels = ['<50', '50-59', '60-69', '70-79', '80+']\n",
    "demographics_df['AGE_RANGE'] = pd.cut(demographics_df['PATIENT_AGE_YEARS'], bins=bins, labels=labels, right=False)\n",
    "demographics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ffbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count and percentage of each gender in population\n",
    "values = demographics_df['GENDER'].value_counts()\n",
    "percents= demographics_df['GENDER'].value_counts(normalize=True) \n",
    "values,percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7095befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count and percentage of each race in population\n",
    "values = demographics_df['PATIENT_RACE'].value_counts()\n",
    "percents= demographics_df['PATIENT_RACE'].value_counts(normalize=True) \n",
    "values,percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a54138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count and percentage of each age group in population\n",
    "values = demographics_df['AGE_RANGE'].value_counts()\n",
    "percents= demographics_df['AGE_RANGE'].value_counts(normalize=True) \n",
    "values,percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701284c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df['HOSP_DISCH_TIME'] = pd.to_datetime(demographics_df['HOSP_DISCH_TIME'])\n",
    "demographics_df['HOSP_ADMSN_TIME'] = pd.to_datetime(demographics_df['HOSP_ADMSN_TIME'])\n",
    "\n",
    "def count_nights(start, end):\n",
    "    # Count full nights between start and end\n",
    "    if end.date() > start.date():\n",
    "        # Calculate the difference in days and subtract 1 for the start day\n",
    "        return (end.date() - start.date()).days\n",
    "    return 0\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "demographics_df['hosp_nights'] = demographics_df.apply(lambda row: count_nights(row['HOSP_ADMSN_TIME'], row['HOSP_DISCH_TIME']), axis=1)\n",
    "\n",
    "# demographics_df['hosp_nights'].value_counts()\n",
    "\n",
    "# Creating hospital night ranges\n",
    "bins = [0, 6, 11, 16, 21, float('inf')]\n",
    "labels = ['1-5', '6-10', '11-15', '16-20', '21+']\n",
    "demographics_df['hosp_nights_ranges'] = pd.cut(demographics_df['hosp_nights'], bins=bins, labels=labels, right=False)\n",
    "\n",
    " # Get count and percentage of each admission length range\n",
    "demographics_df\n",
    "values = demographics_df['hosp_nights_ranges'].value_counts()\n",
    "percents= demographics_df['hosp_nights_ranges'].value_counts(normalize=True) \n",
    "values,percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count and percentage of nights on the unit\n",
    "values = demographics_df['NIGHTS_ON_51600'].value_counts()\n",
    "percents= demographics_df['NIGHTS_ON_51600'].value_counts(normalize=True) \n",
    "values,percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feeefd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count and percentage of admission diagnoses\n",
    "values = demographics_df['ADMISSION_DX_NAME'].value_counts()\n",
    "percents= demographics_df['ADMISSION_DX_NAME'].value_counts(normalize=True) \n",
    "values,percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aac102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of strings that should result in a 1\n",
    "stroke_names = [\n",
    "                'Stroke', \n",
    "                'ICH (intracerebral hemorrhage)', \n",
    "                'SAH (subarachnoid hemorrhage)', \n",
    "                'Cerebrovascular accident (CVA), unspecified mechanism',          \n",
    "                'Subdural hematoma',\n",
    "                'SDH (subdural hematoma)',\n",
    "                'Subarachnoid hemorrhage',\n",
    "                'Intraparenchymal hemorrhage of brain',\n",
    "                'CVA (cerebral vascular accident)',\n",
    "                'Vertebral artery dissection',\n",
    "                'Intracranial hemorrhage',\n",
    "                'Subdural hemorrhage',\n",
    "                'Hemorrhagic stroke',\n",
    "                'Acute ischemic left MCA stroke',\n",
    "                'Basal ganglia hemorrhage',\n",
    "                'Intracerebral hemorrhage',\n",
    "                'Stroke due to embolism of basilar artery',\n",
    "                'ICAO (internal carotid artery occlusion)',\n",
    "                'Cerebral hemorrhage',\n",
    "                'Other left-sided nontraumatic intracerebral hemorrhage',\n",
    "                'Traumatic subarachnoid hematoma with loss of consciousness',\n",
    "                'Occipital stroke',\n",
    "                'Nontraumatic intracerebral hemorrhage, unspecified cerebral location, unspecified laterality',\n",
    "                'Intraventricular hemorrhage',\n",
    "                'Traumatic subarachnoid hemorrhage with loss of consciousness of 30 minutes or less, initial encounter',\n",
    "                'Traumatic right-sided intracerebral hemorrhage with loss of consciousness, initial encounter',\n",
    "                'Intraparenchymal hematoma of brain, left, with unknown loss of consciousness status, initial encounter',\n",
    "                'Cerebellar hemorrhage',\n",
    "                'Intraparenchymal hematoma of brain without loss of consciousness, unspecified laterality, initial encounter',\n",
    "                'ICAO (internal carotid artery occlusion), left',\n",
    "                'Thalamic hemorrhage',\n",
    "                'Traumatic subdural hemorrhage with loss of consciousness of 30 minutes or less, initial encounter',\n",
    "                'Intraparenchymal hematoma of brain, left, without loss of consciousness, initial encounter'         \n",
    "               ]\n",
    "\n",
    "# Create a new binary column based on whether 'col1' equals any of the target strings\n",
    "admission_details['STROKE'] = np.where(admission_details['ADMISSION_DX_NAME'].isin(stroke_names), 1, 0)\n",
    "admission_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797e6a0",
   "metadata": {},
   "source": [
    "### Results: Statistics from the interruption-count algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95727071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics for PSI count\n",
    "psi_count_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d18a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics for LUSO and interruptive episode count\n",
    "luso_epcount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993df857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frequency and percentage of number of PSIs in an interruptuive episode\n",
    "luso_epcount['psis_in_episode'] = luso_epcount['GROUPED_TIMES'].apply(lambda x: [len(sublist) for sublist in x])\n",
    "combined_values = [value for sublist in luso_epcount['psis_in_episode'] for value in sublist]\n",
    "value_counts = Counter(combined_values)\n",
    "value_counts_dict = dict(value_counts)\n",
    "\n",
    "# Create dataframe\n",
    "value_counts_df = pd.DataFrame(value_counts_dict.items(), columns=['PSIs in an Episode', 'Frequency'])\n",
    "value_counts_df = value_counts_df.sort_values(by='PSIs in an Episode', ascending=True)\n",
    "value_counts_df = value_counts_df.reset_index(drop=True)\n",
    "\n",
    "# Add percentage column\n",
    "total_count = value_counts_df['Frequency'].sum()\n",
    "value_counts_df['Percentage'] = (value_counts_df['Frequency'] / total_count) * 100\n",
    "value_counts_df['Percentage'] = value_counts_df['Percentage'].apply(lambda x: '{:.2f}%'.format(x))\n",
    "\n",
    "value_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac7346",
   "metadata": {},
   "source": [
    "### Results: Number of PSIs by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d0b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_df['PSI_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1febc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts_normalized = psi_df['PSI_TYPE'].value_counts(normalize=True)\n",
    "formatted_percentages = value_counts_normalized.map(lambda x: '{:.1f}'.format(x * 100))\n",
    "formatted_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e10b9b7",
   "metadata": {},
   "source": [
    "### Results: Interruptive Episode Count & LUSO Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5068e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "luso_epcount['LUSO_hours'] = 'Unknown'\n",
    "luso_epcount.loc[luso_epcount['LUSO_RANGE'] == '0-59', 'LUSO_hours'] = '0:00-0:59'\n",
    "luso_epcount.loc[luso_epcount['LUSO_RANGE'] == '60-119', 'LUSO_hours'] = '1:00-1:59'\n",
    "luso_epcount.loc[luso_epcount['LUSO_RANGE'] == '120-179', 'LUSO_hours'] = '2:00-2:59'\n",
    "luso_epcount.loc[luso_epcount['LUSO_RANGE'] == '180-239', 'LUSO_hours'] = '3:00-3:59'\n",
    "luso_epcount.loc[luso_epcount['LUSO_RANGE'] == '240-299', 'LUSO_hours'] = '4:00-4:59'\n",
    "luso_epcount.loc[luso_epcount['LUSO_RANGE'] == '300-359', 'LUSO_hours'] = '5:00-5:59'\n",
    "luso_epcount.loc[luso_epcount['LUSO_RANGE'] == '360-419', 'LUSO_hours'] = '6:00-6:59'\n",
    "luso_epcount.loc[luso_epcount['LUSO_RANGE'] == '420-420', 'LUSO_hours'] = '7:00'\n",
    "luso_epcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4362b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = luso_epcount['LUSO_hours'].value_counts()\n",
    "df2 = pd.DataFrame({'Range': df.index, 'Count': df.values})\n",
    "\n",
    "# Extract numerical values from the strings\n",
    "df2['Numerical Value'] = df2['Range'].str.split('-').str[0].str.split(':').str[0].astype(int)\n",
    "\n",
    "# Sort the DataFrame in ascending order based on the numerical value\n",
    "df_sorted = df2.sort_values(by='Numerical Value')\n",
    "df_sorted.drop(columns=['Numerical Value'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac6a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = luso_epcount['NUM_EPISODES'].value_counts()\n",
    "\n",
    "epcount = pd.DataFrame({'Range': df.index, 'Count': df.values})\n",
    "epcount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e580d",
   "metadata": {},
   "source": [
    "### Interruptive Episode and LUSO Duration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a55b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe537c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CDF of interrutpive episode duration\n",
    "sorted_data = episode_durations['Interruptive Episode Duration'].sort_values()\n",
    "cumulative = sorted_data.cumsum() / sorted_data.sum()\n",
    "\n",
    "plt.plot(sorted_data, cumulative, marker='o', linestyle='-', color='blue')\n",
    "plt.xlabel('Duration')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Interruptive Episode Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting LUSO into bins\n",
    "bin_edges = [0, 60, 120, 180, 240, 300, 360, 420, 421]\n",
    "bin_labels = [f'{bin_edges[i]}-{(bin_edges[i+1])-1}' for i in range(len(bin_edges) - 1)]\n",
    "luso_epcount['LUSO_RANGE'] = pd.cut(luso_epcount['LUSO'], bins=bin_edges, labels=bin_labels, right=False)\n",
    "luso_epcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d83e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "luso_epcount['LUSO_RANGE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa3c81",
   "metadata": {},
   "source": [
    "### Results: Pearson's Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37df605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "luso_epcount = luso_epcount[['PAT_ENC_CSN_ID','NUM_EPISODES','LUSO']]\n",
    "luso_epcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = luso_epcount.groupby('PAT_ENC_CSN_ID').mean().reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e0bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trendline(x, y, ax, color):\n",
    "    # Fit a linear trend line to the data\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(x, p(x), color=color)\n",
    "    return z\n",
    "\n",
    "def calculate_correlation(x, y):\n",
    "    correlation_matrix = np.corrcoef(x, y)\n",
    "    correlation = correlation_matrix[0, 1]\n",
    "    return correlation\n",
    "\n",
    "# Create a scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot for Column1 vs Column2\n",
    "ax.scatter(grouped_df['NUM_EPISODES'], grouped_df['LUSO'], color='blue', label='Episode Count vs. LUSO')\n",
    "trendline1 = add_trendline(grouped_df['NUM_EPISODES'], grouped_df['LUSO'], ax, 'blue')\n",
    "corr1 = calculate_correlation(grouped_df['NUM_EPISODES'], grouped_df['LUSO'])\n",
    "\n",
    "\n",
    "# Adding titles and labels\n",
    "ax.set_title('Scatter Plot of Averaged Columns with Trend Lines')\n",
    "ax.set_xlabel('Values')\n",
    "ax.set_ylabel('Values')\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2667f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14ecb18",
   "metadata": {},
   "source": [
    "### Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8475c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = pd.read_csv(r'regression_los_stroke.csv')\n",
    "\n",
    "regression['NIGHT_START'] = pd.to_datetime(regression['NIGHT_START'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import mixedlm\n",
    "\n",
    "\n",
    "# Fit the mixed-effects model\n",
    "model = mixedlm(\"LUSO ~ VITALS +  NEUROS + MEDS + BEDSIDE_TESTING  + OFF_UNIT_TESTING + ON_UNIT_TRANSFER + Days + STROKE\", regression, groups=regression[\"PAT_ENC_CSN_ID\"])\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a89a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract variance components\n",
    "group_variance = result.cov_re.iloc[0, 0]  # Random effect variance\n",
    "residual_variance = result.scale  # Residual variance\n",
    "\n",
    "# Calculate ICC\n",
    "icc = group_variance / (group_variance + residual_variance)\n",
    "print(f\"Intraclass Correlation Coefficient (ICC): {icc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep_kernel",
   "language": "python",
   "name": "sleep_disturbances"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
